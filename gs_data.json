{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "wsmBf7oAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Ying Cheng", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=wsmBf7oAAAAJ&citpid=5", "affiliation": "Fudan University", "organization": 13545734643759689096, "interests": ["Self-Supervised Learning", "Multimodal Analysis"], "email_domain": "@fudan.edu.cn", "citedby": 423, "publications": {"wsmBf7oAAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Look, listen, and attend: Co-attention network for self-supervised audio-visual representation learning", "pub_year": "2020"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:u5HHmVD_uO8C", "num_citations": 138, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6282206625451973735", "cites_id": ["6282206625451973735"]}, "wsmBf7oAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mm-pyramid: Multimodal pyramid attentional network for audio-visual event localization and video parsing", "pub_year": "2022"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:UeHWp8X0CEIC", "num_citations": 81, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6888167211116802998", "cites_id": ["6888167211116802998"]}, "wsmBf7oAAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Modality-aware contrastive instance learning with self-distillation for weakly-supervised audio-visual violence detection", "pub_year": "2022"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:YsMSGLbcyi4C", "num_citations": 61, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13126392927216077162", "cites_id": ["13126392927216077162"]}, "wsmBf7oAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mpn: Multimodal parallel network for audio-visual event localization", "pub_year": "2021"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:9yKSN-GCB0IC", "num_citations": 28, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4862492783711602514", "cites_id": ["4862492783711602514"]}, "wsmBf7oAAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Finemedlm-o1: Enhancing the medical reasoning ability of llm from supervised fine-tuning to test-time training", "pub_year": "2025"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:Se3iqnhoufwC", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16260406713832555025", "cites_id": ["16260406713832555025"]}, "wsmBf7oAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Idea: Increasing text diversity via online multi-label recognition for vision-language pre-training", "pub_year": "2022"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:Tyk-4Ss8FVUC", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3858316667702327064", "cites_id": ["3858316667702327064"]}, "wsmBf7oAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Exploring logical reasoning for referring expression comprehension", "pub_year": "2021"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:qjMakFHDy7sC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4521398609604095982", "cites_id": ["4521398609604095982"]}, "wsmBf7oAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Keep it consistent: Topic-aware storytelling from an image stream via iterative multi-agent communication", "pub_year": "2019"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:u-x6o8ySG0sC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3188631984161213068", "cites_id": ["3188631984161213068"]}, "wsmBf7oAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning music-dance representations through explicit-implicit rhythm synchronization", "pub_year": "2023"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:eQOLeE2rZwMC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15574813406125958101", "cites_id": ["15574813406125958101"]}, "wsmBf7oAAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mixtures of experts for audio-visual learning", "pub_year": "2024"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:roLk4NBRz8UC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3664217919976092983", "cites_id": ["3664217919976092983"]}, "wsmBf7oAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Improving multimodal speech enhancement by incorporating self-supervised and curriculum learning", "pub_year": "2021"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:2osOgNQ5qMEC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8048735950973480338", "cites_id": ["8048735950973480338"]}, "wsmBf7oAAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Self-supervised learning of music-dance representation through explicit-implicit rhythm synchronization", "pub_year": "2022"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:zYLM7Y9cAGgC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15660124335887341137", "cites_id": ["15660124335887341137"]}, "wsmBf7oAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ADSNet: Cross-Domain LTV Prediction with an Adaptive Siamese Network in Advertising", "pub_year": "2024"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:WF5omc3nYNoC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17379681137522178813", "cites_id": ["17379681137522178813"]}, "wsmBf7oAAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "RoBGuard: Enhancing LLMs to Assess Risk of Bias in Clinical Trial Documents", "pub_year": "2025"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:UebtZRa9Y70C", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16264602523821562464", "cites_id": ["16264602523821562464"]}, "wsmBf7oAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "CT2C-QA: Multimodal Question Answering over Chinese Text, Table and Chart", "pub_year": "2024"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:LkGwnXOMwfcC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3824310699594363691", "cites_id": ["3824310699594363691"]}, "wsmBf7oAAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Self-Supervised Video Representation Learning with Motion-Contrastive Perception", "pub_year": "2022"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:ufrVoPGSRksC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=230862208618666118", "cites_id": ["230862208618666118"]}, "wsmBf7oAAAAJ:MXK_kJrjxJIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ConTrack3D: Contrastive Learning Contributes Concise 3D Multi-Object Tracking", "pub_year": "2025"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:MXK_kJrjxJIC", "num_citations": 0}, "wsmBf7oAAAAJ:5nxA0vEk-isC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AS-Det: Active Sampling for Adaptive 3D Object Detection in Point Clouds", "pub_year": "2025"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:5nxA0vEk-isC", "num_citations": 0}, "wsmBf7oAAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Uncertainty-Aware Dynamic Fusion for Multimodal Clinical Prediction Tasks", "pub_year": "2025"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:0EnyYjriUFMC", "num_citations": 0}, "wsmBf7oAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DeepPointMap2: Accurate and Robust LiDAR-Visual SLAM with Neural Descriptors", "pub_year": "2024"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:_FxGoFyzp5QC", "num_citations": 0}, "wsmBf7oAAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FineMedLM-o1: Enhancing Medical Knowledge Reasoning Ability of LLM from Supervised Fine-Tuning to Test-Time Training"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:8k81kl-MbHgC", "num_citations": 0}, "wsmBf7oAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multi-Grained Knowledge for Retrieval-Augmented Question Answering on Hyper-long Contexts"}, "filled": false, "author_pub_id": "wsmBf7oAAAAJ:hqOjcs7Dif8C", "num_citations": 0}}, "citedby5y": 421, "hindex": 9, "hindex5y": 9, "i10index": 9, "i10index5y": 9, "cites_per_year": {"2019": 2, "2020": 4, "2021": 17, "2022": 59, "2023": 83, "2024": 114, "2025": 143}, "updated": "2025-10-28 08:27:24.975675"}